{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645f819a",
   "metadata": {},
   "source": [
    "# VETRA – Sistema Multiagente com LangGraph + Google Gemini\n",
    "\n",
    "Este notebook implementa um MVP funcional do VETRA, um sistema multiagente para avaliação de risco e viabilidade no contexto cripto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1f97a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "from typing import Dict, List, Optional, TypedDict, Any\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d75354f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-17 17:40:53,789 - INFO - Inicializando o modelo Google Gemini...\n",
      "2025-10-17 17:40:53,834 - INFO - Modelo Google Gemini inicializado com sucesso.\n",
      "E0000 00:00:1760733653.829226 2073460 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "# Configuração básica de logs\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "logging.info(\"Inicializando o modelo Google Gemini...\")\n",
    "llm = None\n",
    "\n",
    "try:\n",
    "    GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "    if not GOOGLE_API_KEY:\n",
    "        logging.warning(\"A variável GOOGLE_API_KEY não foi encontrada no .env. O LLM não estará disponível.\")\n",
    "    else:\n",
    "        llm = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.0-flash\",     # Você pode trocar para \"gemini-1.5-flash\" (mais rápido, menor custo)\n",
    "            temperature=0.2,\n",
    "            google_api_key=GOOGLE_API_KEY,\n",
    "            convert_system_message_to_human=True\n",
    "        )\n",
    "        logging.info(\"Modelo Google Gemini inicializado com sucesso.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Erro ao inicializar o Gemini: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7bb637e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VetraState(TypedDict, total=False):\n",
    "    query: str                      # Consulta original do usuário\n",
    "    route: List[str]                # Sequência de agentes a executar\n",
    "    scores: Dict[str, float]        # Pontuações (0..1) de cada agente\n",
    "    rationales: Dict[str, str]      # Explicações curtAS de cada agente\n",
    "    evidence: List[str]             # Evidências agregadas pelos agentes\n",
    "    final_report: str               # Relatório final consolidado\n",
    "    final_json: Dict[str, Any]      # Saída JSON final estruturada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a8338f",
   "metadata": {},
   "source": [
    "# tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#todo: precisa substituir por integrações reais\n",
    "\n",
    "@dataclass\n",
    "class WebResult:\n",
    "    title: str\n",
    "    url: str\n",
    "    snippet: str\n",
    "\n",
    "def web_scrape(query: str) -> List[WebResult]:\n",
    "    \"\"\"substituir por coisas reais\"\"\"\n",
    "    return [\n",
    "        WebResult(title=\"Token X – Site Oficial\", url=\"https://example.com\", snippet=\"Contrato auditado e liquidez travada?\"),\n",
    "        WebResult(title=\"Discussão em Fórum\", url=\"https://forum.example/x\", snippet=\"Relatos de possíveis problemas antigos.\")\n",
    "    ]\n",
    "\n",
    "def fetch_private_data(identifier: str) -> Dict:\n",
    "    \"\"\"apenas simulcao, precisa substituir por coisas reais\"\"\"\n",
    "    return {\n",
    "        \"identifier\": identifier,\n",
    "        \"holders_top10\": 0.76,\n",
    "        \"lp_locked_days\": 2,\n",
    "        \"tx_velocity\": 1.8,\n",
    "        \"age_days\": 11,\n",
    "    }\n",
    "\n",
    "def math_estimator(features: Dict) -> float:\n",
    "    \"\"\"calculo heurístico simples de risco (0..1), precisa substituir por algo mais sofisticado\"\"\"\n",
    "    risk = 0.0\n",
    "    risk += min(1.0, features.get(\"holders_top10\", 0) * 0.8)\n",
    "    risk += 0.2 if features.get(\"lp_locked_days\", 0) < 7 else 0.0\n",
    "    risk += 0.1 if features.get(\"age_days\", 0) < 14 else 0.0\n",
    "    return max(0.0, min(1.0, risk))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495274b1",
   "metadata": {},
   "source": [
    "# prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e8f7e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SYSTEM_SUP = SystemMessage(content=(\n",
    "    'Você é o Supervisor do VETRA. Com base na consulta do usuário, decida quais agentes devem ser executados. '\n",
    "    'Agentes disponíveis: phishing, transaction, rugpull. '\n",
    "    'Responda APENAS com um JSON válido exatamente neste formato: {\"route\":[\"phishing\",\"rugpull\"]}. '\n",
    "    \"Inclua somente a chave 'route' com os nomes válidos em minúsculas.\"\n",
    "))\n",
    "\n",
    "SYSTEM_AGENT = SystemMessage(content=(\n",
    "    \"Você é um analista de risco cripto do VETRA. Sempre responda com:\\n\"\n",
    "    \"1) SCORE(0..1) na primeira linha (com três casas decimais)\\n\"\n",
    "    \"2) Em seguida, uma explicação curta (no máximo 4 frases).\"\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48feaaa8",
   "metadata": {},
   "source": [
    "\n",
    "# agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed36f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_node(state: VetraState) -> VetraState:\n",
    "    \"\"\"Decide a lista de agentes a executar com base na query do usuário\"\"\"\n",
    "    user_q = state[\"query\"].strip()\n",
    "    msg = [SYSTEM_SUP, HumanMessage(content=user_q)]\n",
    "    raw = llm.invoke(msg).content if llm else \"phishing,transaction,rugpull\"\n",
    "    csv = raw.strip().lower()\n",
    "\n",
    "    valid = []\n",
    "    for part in re.split(r\"[\\,\\n;\\s]+\", csv):\n",
    "        if part in {\"phishing\", \"transaction\", \"rugpull\"} and part not in valid:\n",
    "            valid.append(part)\n",
    "    if not valid:\n",
    "        valid = [\"phishing\"]\n",
    "\n",
    "    return {**state, \"route\": valid, \"scores\": {}, \"rationales\": {}, \"evidence\": []}\n",
    "\n",
    "\n",
    "def phishing_agent_node(state: VetraState) -> VetraState:\n",
    "    query = state[\"query\"]\n",
    "    results = web_scrape(query)\n",
    "    snippets = \"\\n\".join([f\"- {r.title} | {r.url} | {r.snippet}\" for r in results])\n",
    "\n",
    "    prompt = f\"Analise possível phishing relacionado a: {query}.\\nEvidências:\\n{snippets}\\nAvalie o risco.\"\n",
    "    out = llm.invoke([SYSTEM_AGENT, HumanMessage(content=prompt)]).content.strip() if llm else \"0.2\\nSite parece legítimo e usa SSL válido.\"\n",
    "    score = _extract_score(out)\n",
    "    rationale = out.split(\"\\n\", 1)[1] if \"\\n\" in out else \"\"\n",
    "\n",
    "    state[\"scores\"][\"phishing\"] = score\n",
    "    state[\"rationales\"][\"phishing\"] = rationale\n",
    "    state[\"evidence\"].append(snippets)\n",
    "    \n",
    "    route = state.get(\"route\", [])\n",
    "    if \"phishing\" in route:\n",
    "        route.remove(\"phishing\")\n",
    "        state[\"route\"] = route\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def transaction_agent_node(state: VetraState) -> VetraState:\n",
    "    identifier = _first_wallet_or_tx(state[\"query\"]) or \"unknown\"\n",
    "    feats = fetch_private_data(identifier)\n",
    "\n",
    "    prompt = f\"Analise comportamento on-chain. Dados: {feats}\\nForneça SCORE de risco e uma justificativa curta.\"\n",
    "    out = llm.invoke([SYSTEM_AGENT, HumanMessage(content=prompt)]).content.strip() if llm else \"0.7\\nTransações concentradas em poucas carteiras.\"\n",
    "    score = _extract_score(out)\n",
    "    rationale = out.split(\"\\n\", 1)[1] if \"\\n\" in out else \"\"\n",
    "\n",
    "    state[\"scores\"][\"transaction\"] = score\n",
    "    state[\"rationales\"][\"transaction\"] = rationale\n",
    "    state[\"evidence\"].append(str(feats))\n",
    "    \n",
    "    route = state.get(\"route\", [])\n",
    "    if \"transaction\" in route:\n",
    "        route.remove(\"transaction\")\n",
    "        state[\"route\"] = route\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def rugpull_agent_node(state: VetraState) -> VetraState:\n",
    "    identifier = _first_token(state[\"query\"]) or \"tokenX\"\n",
    "    feats = fetch_private_data(identifier)\n",
    "    heuristic = math_estimator(feats)\n",
    "\n",
    "    prompt = f\"Analise risco de rugpull. Features: {feats}\\nHeurística preliminar: {heuristic:.3f}\\nForneça SCORE final e justificativa curta.\"\n",
    "    out = llm.invoke([SYSTEM_AGENT, HumanMessage(content=prompt)]).content.strip() if llm else \"0.9\\nLiquidez destrava em breve; risco elevado.\"\n",
    "    score = _extract_score(out)\n",
    "    rationale = out.split(\"\\n\", 1)[1] if \"\\n\" in out else \"\"\n",
    "\n",
    "    # Combinação simples entre o score do modelo e a heurística para estabilidade\n",
    "    score = float(min(1.0, max(0.0, 0.7 * score + 0.3 * heuristic)))\n",
    "\n",
    "    state[\"scores\"][\"rugpull\"] = score\n",
    "    state[\"rationales\"][\"rugpull\"] = rationale\n",
    "    state[\"evidence\"].append(str(feats))\n",
    "    \n",
    "    route = state.get(\"route\", [])\n",
    "    if \"rugpull\" in route:\n",
    "        route.remove(\"rugpull\")\n",
    "        state[\"route\"] = route\n",
    "    \n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d55e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _extract_score(text: str) -> float:\n",
    "    \"\"\"Extrai o valor SCORE (0..1) da primeira linha de texto do agente.\"\"\"\n",
    "    first = text.split(\"\\n\", 1)[0]\n",
    "    m = re.search(r\"([01](?:\\.\\d+)?)\", first)\n",
    "    try:\n",
    "        val = float(m.group(1)) if m else 0.5\n",
    "    except Exception:\n",
    "        val = 0.5\n",
    "    return max(0.0, min(1.0, val))\n",
    "\n",
    "\n",
    "def _first_wallet_or_tx(q: str) -> Optional[str]:\n",
    "    m = re.search(r\"0x[a-fA-F0-9]{6,}\", q)\n",
    "    return m.group(0) if m else None\n",
    "\n",
    "\n",
    "def _first_token(q: str) -> Optional[str]:\n",
    "    m = re.search(r\"\\b[A-Z]{2,10}\\b\", q)\n",
    "    return m.group(0) if m else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trust_index_node(state: VetraState) -> VetraState:\n",
    "    \"\"\"Agrega os resultados dos agentes e produz um relatório final e valores em JSON.\"\"\"\n",
    "    scores = state.get(\"scores\", {})\n",
    "    weights = {\"phishing\": 0.35, \"transaction\": 0.30, \"rugpull\": 0.35}\n",
    "\n",
    "    num = sum(weights.get(k, 0.0) * v for k, v in scores.items())\n",
    "    den = sum(weights.values())\n",
    "    trust_index = num / den if den else 0.0\n",
    "\n",
    "    bullets = [f\"- {k.title()}: {scores[k]:.3f} — {state['rationales'].get(k, '')}\" for k in scores]\n",
    "    report = f\"VETRA Trust Index: {trust_index:.3f} (0 = seguro, 1 = risco alto)\\n\\n\" + \"\\n\".join(bullets)\n",
    "    state[\"final_report\"] = report\n",
    "\n",
    "    # JSON estruturado (guardado no estado para exibição posterior)\n",
    "    state[\"final_json\"] = {\n",
    "        \"trust_index\": round(trust_index, 3),\n",
    "        \"scores\": {k: round(v, 3) for k, v in scores.items()},\n",
    "        \"rationales\": state.get(\"rationales\", {}),\n",
    "        \"evidence\": state.get(\"evidence\", []),\n",
    "        \"final_report\": report\n",
    "    }\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74192310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph():\n",
    "    graph = StateGraph(VetraState)\n",
    "    graph.add_node(\"supervisor\", supervisor_node)\n",
    "    graph.add_node(\"phishing\", phishing_agent_node)\n",
    "    graph.add_node(\"transaction\", transaction_agent_node)\n",
    "    graph.add_node(\"rugpull\", rugpull_agent_node)\n",
    "    graph.add_node(\"trust_index\", trust_index_node)\n",
    "\n",
    "    graph.set_entry_point(\"supervisor\")\n",
    "\n",
    "    def choose_next(state: VetraState):\n",
    "        route = state.get(\"route\", [])\n",
    "        if not route:\n",
    "            return \"trust_index\"\n",
    "        nxt = route.pop(0)\n",
    "        state[\"route\"] = route\n",
    "        return nxt\n",
    "\n",
    "    def route_after_agent(state: VetraState):\n",
    "        route = state.get(\"route\", [])\n",
    "        if not route:\n",
    "            return \"trust_index\"\n",
    "        return \"supervisor\"\n",
    "\n",
    "    graph.add_conditional_edges(\"supervisor\", choose_next, {\n",
    "        \"phishing\": \"phishing\",\n",
    "        \"transaction\": \"transaction\", \n",
    "        \"rugpull\": \"rugpull\",\n",
    "        \"trust_index\": \"trust_index\",\n",
    "    })\n",
    "\n",
    "    for node in [\"phishing\", \"transaction\", \"rugpull\"]:\n",
    "        graph.add_conditional_edges(node, route_after_agent, {\n",
    "            \"supervisor\": \"supervisor\",\n",
    "            \"trust_index\": \"trust_index\"\n",
    "        })\n",
    "\n",
    "    graph.add_edge(\"trust_index\", END)\n",
    "    return graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f5cdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- RELATÓRIO FINAL ---------\n",
      "VETRA Trust Index: 0.350 (0 = seguro, 1 = risco alto)\n",
      "\n",
      "- Phishing: 1.000 — \n",
      "2) O token ABC (0x1234567890) apresenta risco moderado. Embora o site oficial (example.com) indique auditoria e liquidez travada, a discussão em fórum (forum.example/x) levanta preocupações com relatos de problemas antigos. É crucial investigar a natureza desses problemas e a reputação da equipe por trás do token para mitigar o risco de rugpull ou phishing. A auditoria e o bloqueio de liquidez são positivos, mas não eliminam totalmente o risco.\n",
      "-----------------------------------\n",
      "\n",
      "--------- SAÍDA JSON ---------\n",
      "{\n",
      "  \"trust_index\": 0.35,\n",
      "  \"scores\": {\n",
      "    \"phishing\": 1.0\n",
      "  },\n",
      "  \"rationales\": {\n",
      "    \"phishing\": \"\\n2) O token ABC (0x1234567890) apresenta risco moderado. Embora o site oficial (example.com) indique auditoria e liquidez travada, a discussão em fórum (forum.example/x) levanta preocupações com relatos de problemas antigos. É crucial investigar a natureza desses problemas e a reputação da equipe por trás do token para mitigar o risco de rugpull ou phishing. A auditoria e o bloqueio de liquidez são positivos, mas não eliminam totalmente o risco.\"\n",
      "  },\n",
      "  \"evidence\": [\n",
      "    \"- Token X – Site Oficial | https://example.com | Contrato auditado e liquidez travada?\\n- Discussão em Fórum | https://forum.example/x | Relatos de possíveis problemas antigos.\"\n",
      "  ],\n",
      "  \"final_report\": \"VETRA Trust Index: 0.350 (0 = seguro, 1 = risco alto)\\n\\n- Phishing: 1.000 — \\n2) O token ABC (0x1234567890) apresenta risco moderado. Embora o site oficial (example.com) indique auditoria e liquidez travada, a discussão em fórum (forum.example/x) levanta preocupações com relatos de problemas antigos. É crucial investigar a natureza desses problemas e a reputação da equipe por trás do token para mitigar o risco de rugpull ou phishing. A auditoria e o bloqueio de liquidez são positivos, mas não eliminam totalmente o risco.\"\n",
      "}\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "app = build_graph()\n",
    "\n",
    "# Exemplo de consulta \n",
    "consulta = \"Analise o token ABC 0x1234567890 e verifique risco de rugpull e phishing.\"\n",
    "\n",
    "resultado = app.invoke({\"query\": consulta})\n",
    "\n",
    "# Exibir relatório legível\n",
    "print(\"--------- RELATÓRIO FINAL ---------\")\n",
    "print(resultado.get(\"final_report\", \"(nenhum relatório gerado)\"))\n",
    "print(\"-----------------------------------\\n\")\n",
    "\n",
    "# Exibir JSON estruturado\n",
    "final_json = resultado.get(\"final_json\", {})\n",
    "print(\"--------- SAÍDA JSON ---------\")\n",
    "print(json.dumps(final_json, ensure_ascii=False, indent=2))\n",
    "print(\"--------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ccccf4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
